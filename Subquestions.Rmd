---
title: "Pesticide Labels Now Report"
subtitle: "Draft"
date: "`r Sys.Date()`"
output:
  md_document:
    toc: yes
  html_document:
    code_folding: hide
    self_contained: yes
    toc: no
    toc_depth: 4
    toc_float: yes
  pdf_document:
    latex_engine: xelatex
    toc: yes
    toc_depth: 4
  word_document:
    toc: yes
    toc_depth: '4'
#editor_options: 
  #chunk_output_type: console
---

```{r packages, warning=F, message=F, echo=F, results=F}

if(!require(pacman)) {install.packages("pacman")}
pacman::p_load(tidyverse, utils, lubridate, readxl, vcd, kableExtra, table1, here, maps, sf, ggmap, sp, ggthemes, ggspatial, urbnmapr, breakDown, dplyr, expm, devtools, data.table, ggplot2, car, viridis, ggExtra, tidyr, tigris, frequency)

#install summary tools package later
devtools::install_github("yutannihilation/ggsflabel")
devtools::install_github("UrbanInstitute/urbnmapr")

```

```{r setup, include=F, results='asis', eval = F}

st_options(plain.ascii = F, # Always use this option in Rmd documents
style        = "rmarkdown", # Always use this option in Rmd documents
footnote     = NA,          # Makes html-rendered results more concise
subtitle.emphasis = F)  # Improves layout with some rmarkdown themes

```

```{r upload-clean-data, warning=F, message=F, echo=F, results=F}

temp <- list.files(path='Outputs', pattern="*.csv", full.names = T)

list2env(lapply(setNames(temp, make.names(gsub("*.csv$", "", temp))), read.csv), envir = .GlobalEnv)

colnames(Outputs.evStart.1)[1] <- "aid"
colnames(Outputs.evStart.1)[2] <- "evDesc1"
colnames(Outputs.evStart.1)[3] <- "evDesc2"
colnames(Outputs.evStart.1)[4] <- "evDesc3"
colnames(Outputs.evStart.1)[5] <- "evType"
colnames(Outputs.evStart.1)[6] <- "ts"

Outputs.evStart <- do.call(rbind, lapply(ls(pattern = "Outputs.evStart"), get))

rm(list = ls()[grep("^Outputs.evStart.", ls())])

#Filter out ignores

ignores <- read.csv("ignores.csv")

evDownload.01 <- filter(Outputs.evDownload.01,!(aid %in% ignores$aid))

evStart <- filter(Outputs.evStart,!(aid %in% ignores$aid))

evViewPage.01 <- filter(Outputs.evViewPage.01,!(aid %in% ignores$aid))

rm(Outputs.evDownload.01, Outputs.evStart, Outputs.evViewPage.01)

```

# How do user characteristics inform or explain their interaction with the 'Pesticides Labels Now' application? 
## Authors: 
  - Aarti Tandon:
    url: https://github.com/aartitandon/SURE-EH-Research-Project
    ![alt text](IMG_7470 2.JPG)
    
    

<br>

# Executive Summary
The ‘Pesticides Labels Now!’ mobile application strives to minimize agricultural worker and community exposure and illness from agricultural pesticides through improving access to pesticide labels and safety information in Spanish and English. Pesticide handlers, managers, and supervisors are able to gain access to this information, change behaviors accordingly, and transfer the safety information to others. We hypothesized that user characteristics such as language choice, mobile device type, and location would determine frequency of interactions with the application. This study investigates the application’s user audience and their preferences for app utility. Statistical analysis and graphing was conducted with R Studio (Version 2021.09.1) for users accessing the application over one year starting in August 2020. The raw data set consisted primarily of users from the State of Washington, containing 67,754 interactions and a total of 503 unique users. The results showed that user utilization is predominantly concentrated in central Washington, which is part of the Columbia Basin, and has very productive agricultural land. The overall frequency of each language accessed on the application was relatively comparable - with 59% in English and 41% in Spanish. The analysis further indicated the majority of users utilize the application through an iOS system. An estimated 74% of interactions were accessed through an iPhone device and 26% were accessed through an Android device. By understanding the effect of user characteristics in their interaction with the application, necessary adjustments can be made to the application to create a more user-friendly experience and contribute to improving access to pesticide labels and their safety information. 

# Objective
## To understand the 'Pesticide Labels Now' mobile application user audience and their preferences for app utility. 

# Features to Help Understand User Characteristics 
- Location 
- Device 
- Language 

# Data Subsets
A data dictionary and descriptive statistics were prepared based on the Pesticide Labels Now (PLN) [analysis plan](https://docs.google.com/document/d/1mUHPYdpWljCWroODGenUjYlyae2ZWwqN4MScBLXlr2U/edit). For a better representation of users, we ignored a list of random identifiers ('aid' in *ignores.csv*) associated with the project team members and generated descriptive statistics for three subsets:

- evDownload.01
- evStart
- evViewPage.01

# Descriptive Statistics

## evDownload.01

```{r evDownload-summary, eval=F, warning=F, message=F, echo=F, results='asis'}
library("frequency")

print(freq(evDownload.01$prodName, report.nas = F, totals = T, cumul = F, headings = T, order="freq", style = 'rmarkdown'))

print(freq(evDownload.01$sourcePage, report.nas = F, totals = T, cumul = F, headings = T, order="freq", style = 'rmarkdown'))

print(freq(evDownload.01$evType, report.nas = F, totals = T, cumul = F, headings = T, order="freq", style = 'rmarkdown'))

#print(ctable(x = evDownload.01$evType, y = evDownload.01$sourcePage, prop = "r", style='rmarkdown'))

#print(freq(evDownload.01$aid, report.nas = F, totals = T, cumul = F, headings = T, order="freq"), method="render")

```

## evStart

```{r evStart-summary, warning=F, message=F, echo=F, results='asis'}

#print(freq(evStart$evDesc1, report.nas = F, totals = T, cumul = F, headings = T, order="freq", style = 'rmarkdown'))

#Tally device type using evDesc2 (all sessions)

evStart$evDesc2 <- as.character(evStart$evDesc2)

s <- strsplit(evStart$evDesc2, split = ",")

evStart$device_cat <- unlist(purrr::map(s, 1))

rm(s)

#Tally device types using evDesc2 (unique aid)

evStart.unique.device <- evStart %>%
  distinct_at(vars(aid), .keep_all = TRUE)

#print(freq(evStart.unique.device$device_cat, report.nas = F, totals = T, cumul = F, headings = T, order="freq", style = 'rmarkdown'))

#print(freq(evStart$evDesc3, report.nas = F, totals = T, cumul = F, headings = T, order="freq"), method="render")

#print(freq(evStart$evType, report.nas = F, totals = T, cumul = F, headings = T, order="freq", style = 'rmarkdown'))

#print(freq(evStart$aid, report.nas = F, totals = T, cumul = F, headings = T, order="freq"), method="render")

```

## evViewPage.01

```{r evViewPage-summary, eval=F, warning=F, message=F, echo=F, results='asis'}

print(freq(evViewPage.01$evDesc1, report.nas = F, totals = T, cumul = F, headings = T, order="freq", style = 'rmarkdown'))

print(freq(evViewPage.01$evDesc2, report.nas = F, totals = T, cumul = F, headings = T, order="freq", style = 'rmarkdown'))

print(freq(evViewPage.01$evDesc3, report.nas = F, totals = T, cumul = F, headings = T, order="freq", style = 'rmarkdown'))

print(freq(evViewPage.01$evType, report.nas = F, totals = T, cumul = F, headings = T, order="freq", style = 'rmarkdown'))

#print(freq(evViewPage.01$aid, report.nas = F, totals = T, cumul = F, headings = T, order="freq"), method="render")

```

# App Use By Location  
## Plot for US Sessions
```{r user-map-us, warning=F, message=F, echo=F, eval=T, out.width = "100%", fig.cap = "An amazing plot"}

#extract locations from evStart
## Remove parenthesizes from evDesc3 lat, long
evStart$evDesc3sub <- gsub("[()]", "", evStart$evDesc3)

## Separate lat/long
evStart <- evStart %>%
     filter(evDesc3sub != '0,0') %>%
     separate(evDesc3sub, into = c('lat','lon'), sep=",")

gps <- select(evStart, lat, lon)
gps <- na.omit(gps)
gps <- gps[gps$lat != NaN, ]
gps$lat <- as.numeric(gps$lat)
gps$lon <- as.numeric(gps$lon)

pln_sf <- gps %>% st_as_sf(coords = c("lon","lat"), crs=4326)
pln_sf_t <- st_transform(pln_sf, crs=2163)

library(urbnmapr)
states_sf <- get_urbn_map(map = "states", sf = T)

#Plot for US sessions

ggplot() + 
  geom_sf(data = pln_sf_t, color="red", size=1) + 
  geom_sf(data = states_sf, fill=NA, color="black", size=0.1, alpha=0) +
  coord_sf(datum = st_crs(2163)) +
  labs(fill = "", title="", caption="") + scale_x_continuous(limits = c(-3e+06, 3e+06)) +
    scale_y_continuous(limits = c(-3e+06, 1e+06)) + theme_nothing() 
```

## Plot for WA sessions

```{r user-map-wa, echo=F, warning=F, message=F, eval=T, out.width = "100%"}

#Plot for WA sessions

library(devtools)
library(urbnmapr)

counties_sf <- get_urbn_map(map = "counties", sf = T)

pln_sf_t <- st_transform(pln_sf, crs=2285)
counties_sf_t <- st_transform(counties_sf, crs=2285)

t <- counties_sf_t %>%
  filter(state_name == "Washington")

ggplot() + 
  geom_sf(data = pln_sf_t, color="red", size=1) + 
  geom_sf(data = t, fill=NA, color="black", size=0.1, alpha=0) +
  coord_sf(datum = st_crs(2285)) +
  labs(fill = "", title="", caption="") + scale_x_continuous(limits = c(0.6e+06, 2.7e+06)) +
    scale_y_continuous(limits = c(-0.7e+06, 0.8e+06)) + theme_nothing()

```


```{r user-map-wa-kingcounty, warning=F, message=F, echo=F, eval=T, out.width = "100%"}

library(ggplot2)
library(dplyr, warn.conflicts = FALSE)
library(ggsflabel, warn.conflicts = FALSE)
library(tigris, warn.conflicts = FALSE)

wa_state <- states(cb = TRUE, class = "sf") %>% 
  filter(NAME == "Washington")

wa_county <- counties(state = "WA", cb = TRUE, class = "sf")

wa_study_counties <- wa_county 
```

## Plot for WA sessions with County Names

```{r user-map-wa-allcounties, echo=F, warning=F, message=F, eval=T, out.width = "100%"}

wa_study_counties <- wa_county %>% 
  filter(NAMELSAD %in% c("King County", "Whatcom County", "Chelan County", "Douglas County", "Grant County", "Yakima County", "Lewis County", "Klickitat County", "Benton County", "Franklin County", "Walla Walla County", "Pierce County", "Clark County"))
  
 ggplot() + 
  geom_sf(fill="gray") +
  geom_sf(data = pln_sf_t, color="red", size=1) + 
  geom_sf(data = t, fill=NA, color="black", size=0.1, alpha=0) +
  geom_sf(data = wa_county, fill = NA) +
  geom_sf_label_repel(data = wa_study_counties, aes(label = NAMELSAD), force = 50) +
  coord_sf(datum = st_crs(2285)) +
  labs(fill = "", title="", caption="") + scale_x_continuous(limits = c(0.6e+06, 2.7e+06)) +
    scale_y_continuous(limits = c(-0.7e+06, 0.8e+06)) + theme_nothing()
 
 #maybe turn off county labels? 
 #scatterplot dodge to avoid overlapping of redcirclemappers 
 #https://ggplot2.tidyverse.org/reference/position_dodge.html
```

```{r heat-map-time-series, warning=F, message=F, echo=F} 

#all accesses by date

#https://towardsdatascience.com/time-series-calendar-heatmaps-9f576578fcfe

#calendar day x individual

#https://www.littlemissdata.com/blog/heatmaps

```

```{r summary, eval=F, warning=F, message=F, echo=F}

print(dfSummary(evDownload.01), method = "render")
print(dfSummary(evStart), method = "render")
print(dfSummary(evViewPage.01), method = "render")
print(dfSummary(Outputs.h.s.label.view.counts), method = "render")
print(dfSummary(Outputs.HS.DLS.2021), method = "render")
print(dfSummary(Outputs.PICOL.DLS.2021), method = "render")

```

```{r upload-merged-monthly-csvs, warning=F, message=F, echo=F, results=F}
# merged.csv dataframe 

temp <- list.files(path='CSV', pattern="*.csv", full.names = T)
list2env(lapply(setNames(temp, make.names(gsub("*.csv$", "", temp))), read.csv), envir = .GlobalEnv)
rm(CSV.qAnswers)
merged.csv <- do.call(rbind, lapply(ls(pattern = "CSV"), get))
ignores <- read.csv("ignores.csv")
merged.csv <- filter(merged.csv,!(aid %in% ignores$aid))
```

# App Use by Device

```{r creating-sessions, warning=F, message=F, echo=F, eval=T}

# Goal: Creating Sessions. 
# 1327 total sessions from 2020-08-26 through 2021-08-31. This doesn't include any sessions initiated by one of the 'ignored' aids.

library("dplyr")
library("lubridate")

#filter merged.csv from aid's first "evStart" to the next "evStart"
merged.csv.dedup <- unique(merged.csv)

x <- merged.csv.dedup %>% 
  group_by(sessionid = cumsum(evType == 'evStart')) %>% 
  mutate(sessioneventno = row_number())

x$ts <- ymd_hms(x$ts)

```

## Devices Utilized to Access the Application

```{r analyzing-devices, warning=F, message=F, echo=F, results=F, eval=T}
# SubQuestion #1: Which operating systems are utilized to access the application? 

str(evStart)
per_data <- evStart %>%
  count(device_cat) %>% 
  mutate(per = n / sum(n),
         per_label = paste0(round(per*100), "%"))

library(ggplot2)
ggplot(per_data, aes(x = reorder(n, -per), y=per)) + 
  geom_bar(stat = "identity", fill = "darkseagreen1", color = "black") + 
  geom_text(aes(label=per_label), vjust=-0.25) + 
  labs(x = "Devices", y = "Count",  
       title = "Devices Utilized to Access the Application") + 
  theme_bw() + 
  scale_x_discrete(labels = c("iPhone", "Android", "iPad", "Pixel 3a: Android 10"))
```

# App Use by Language
## Frequency of Each Language Accessed on the Application
```{r analyzing-language-frequency, warning=F, message=F, echo=F, results=F, eval=T}
# SubQuestion #2: Which language is more frequently utilized with the 'Pesticide Labels Now' application? 

library("dplyr")
count_Language <- evViewPage.01 %>%
  count(evDesc2)

library(tidyverse)

str(evViewPage.01)
per_data2 <- evViewPage.01 %>%
  count(evDesc2) %>% 
  mutate(per = n / sum(n),
         per_label = paste0(round(per*100), "%"))

ggplot(per_data2, aes(x = reorder(n, -per), y=per)) + 
  geom_bar(stat = "identity", fill = "lightblue", color = "black") + 
  geom_text(aes(label=per_label), vjust=-0.25) + 
  labs(x = "Language", y = "Count",  
       title = "Frequency of Each Language Accessed on the Application") + 
  theme_bw() + 
  scale_x_discrete(labels = c("English", "Spanish"))
```

```{r device_cat_aid, warning=F, message=F, echo=F, results=F, eval=T}

# Retrieving each ID's device and accessed language
library(tidyr)
library(ggplot2)

device_cat_aid <- unique(evStart[ , c("aid", "device_cat")])
aid_device_language <- left_join(evViewPage.01, device_cat_aid, by="aid") 

table(aid_device_language$evDesc2, aid_device_language$device_cat)
```

```{r freq-of-lang-by-device-with-percents, warning=F, message=F, echo=F, results=F, eval=F}
# Frequency of Different Languages by Device w/ Percentage Labels 
# the percentages are not accurately placed

ggplot(aid_device_language, aes(x=evDesc2)) + 
  geom_bar(aes(y = 2*(..count..)/sum(..count..), fill = device_cat, group=device_cat), stat="count") +
  geom_label(aes(label = scales::percent(2*(..count..)/sum(..count..)),
                  group = device_cat), position = "fill", stat= "count", vjust = 0) +
  labs(y = "Percent", fill="device_cat") +
  scale_y_continuous(labels = scales::percent)
  
```

## Frequency of Different Languages by Operating System 
```{r freq-of-lang-by-operating-system, warning=F, message=F, echo=F, results=F, eval=T}
#Without percentage labels 
library(car)
aid_device_language2 <- aid_device_language
aid_device_language2$device_cat <- recode(aid_device_language2$device_cat,"c('iphone') = 'iOS'")
aid_device_language2$device_cat <- recode(aid_device_language2$device_cat,"c('ipad') = 'iOS'")
aid_device_language2$device_cat <- recode(aid_device_language2$device_cat,"c('android') = 'Android'")
#aid_device_language2$device_cat <- recode(aid_device_language2$device_cat,"c('Pixel 3a: Android 10') = 'Android'")
#aid_device_language2$device_cat <- case_when(aid_device_language2$device_cat == "Pixel 3a: Android 10" ~ "android", TRUE ~ NA)


aid_device_language2 <- filter(aid_device_language2, !is.na(device_cat))

aid_device_language2 <- filter(aid_device_language2, !is.na(evDesc2))

which(is.na(aid_device_language2), arr.ind=TRUE)

ggplot(data = aid_device_language2, aes(x = evDesc2, fill = device_cat)) + 
  geom_bar(position = "fill") + 
  scale_y_continuous(labels = function(x) paste0(x*100, "%")) + 
   labs(title = "Frequency of Different Languages by Operating System", 
       x = "Language", 
       y = "Percentage") +
      scale_x_discrete(labels = c("English", "Spanish")) +
      scale_fill_discrete(name = "Operating System", labels = c("Android", "iOS"))  
```

```{r, eval=F, echo=F}
# Subquestion #4: What is the average number of labels looked at per session? 

#Notes from Dennis on ‘How to find Number of Labels Search Per User in a Session’:
# 1. Sort the list by aid 
# 2. Sort by time stamp (not that it matters)
# 3. Iterate through the list from (1) evStart 
# 4. Set up a counter - evViewHS , from one evStart to the next evStart 
```


```{r creating sessions, warning=F, message=F, echo=F, results=F, eval=T}

# Y = unique Sessions including activity, start time, end time, etc. 

library(data.table)
library(dplyr)
library(ggplot2)
library(lubridate)

merged.csv.dedup <- unique(merged.csv)

x <- merged.csv.dedup %>% 
  group_by(sessionid = cumsum(evType == 'evStart')) %>% 
  mutate(sessioneventno = row_number())

x$ts <- ymd_hms(x$ts)
x$ts <- force_tz(x$ts, "UTC")

setDT(x)
y <- x[ , .(session_start = min(ts), session_end = max(ts), num_occurance = .N), by = sessionid]

#'session time' column is added 
y$sessiontime <- ymd_hms(y$session_end) - ymd_hms(y$session_start)
y$sessiontime2 <- as.double(y$sessiontime)
y$sessiontimemin <- y$sessiontime2/60

```

# App Use By Time

## Comparing User Sessions by 'Day of the Month', 'Month', and 'Activity of the User'
```{r heatmap1, warning=F, message=F, echo=F, results=F, eval=T}
# x=day, y=month, fill="activity"/number of occurances

library(lubridate)
y$hour <- hour(y$session_start)
y$day <- day(y$session_start)
y$week <- week(y$session_start)
y$month <- month(y$session_start)
y$month <- month.abb[as.numeric(y$month)]
# (the line above converts month number to month name)
y$year <- year(y$session_start)
y$month = factor(y$month, levels = month.abb)

ggplot(y, aes(x=day, y=month)) + geom_tile(aes(fill=num_occurance)) +
  labs(x="Day of the Month",
       y="Month",
       title = "2020-2021 Calendar Heatmap", 
       fill="Activity of the User")
       
```

## Comparing User Sessions by 'Hour of the Day', 'Day of the Month', and 'Activity of the User'
```{r heatmap2, warning=F, message=F, echo=F, results=F, eval=T}

# x=hour of the day, y=day of the month, fill="activity"/number of occurances
ggplot(y, aes(x=hour, y=day)) + geom_tile(aes(fill=num_occurance)) +
  labs(x="Hour of The Day",
       y="Day of the Month",
       title = "2020-2021 Calendar Heatmap", 
       fill="Activity of the User")
       
```

## Comparing User Sessions by 'Day of the Month', 'Month', and 'Session Time (in minutes)'
```{r heatmap3, warning=F, message=F, echo=F, results=F, eval=T}
# heatmap attempt 6 (this is the one included in the poster)
# sessiontime is done in seconds here 

ggplot(y, aes(x=day, y=month)) + geom_tile(aes(fill=sessiontimemin)) + 
scale_y_discrete(limits = month.abb) + 
 labs(x="Day of the Month",
       y="Month",
       title = "2020-2021 Calendar Heatmap", 
       fill="Session Time (minutes)")
```

## Comparing User Sessions by 'Hour of the Month', 'Day of the Month', 'Month', and 'Year'
```{r heatmap4, warning=F, message=F, echo=F, results=F, eval=T}

library(ggplot2)
library(dplyr) #easier data wrangling 
library(viridis) #colour blind friendly palette, works in B&W also
library(lubridate) 
library(ggExtra) #because remembering ggplot theme options is beyond me
library(tidyr) 

df <-y %>% select(sessionid,day,hour,month,year)
p <-ggplot(df,aes(day,hour))+
  geom_tile(color= "white",size=0.1) + 
  scale_fill_viridis(name="Hrly Temps C",option ="C")
p <-p + facet_grid(year~month)
p <-p + scale_y_continuous(trans = "reverse", breaks = unique(df$hour))
p <-p + scale_x_continuous(breaks =c(1,10,20,31))
p <-p + theme_minimal(base_size = 8)
p <-p + labs(title= paste("Session Analytics"), x="Day of the Month", y="Hour Commencing")
p <-p + theme(legend.position = "bottom")+
  theme(plot.title=element_text(size = 14))+
  theme(axis.text.y=element_text(size=6)) +
  theme(strip.background = element_rect(colour="white"))+
  theme(plot.title=element_text(hjust=0))+
  theme(axis.ticks=element_blank())+
  theme(axis.text=element_text(size=7))+
  theme(legend.title=element_text(size=8))+
  theme(legend.text=element_text(size=6))

p

```

# App Use By Activity 
## Frequency of Each Source Page Accessed on the Application 
```{r source-page, echo=F, warning=F, message=F, results=F, eval=T, fig.width = 7, fig.height=7}
str(evDownload.01)
download_data <- evDownload.01 %>%
  count(sourcePage) %>% 
  mutate(per = n / sum(n),
         per_label = paste0(round(per*100), "%"))

ggplot(download_data, aes(x = reorder(n, -per), y=per)) + 
  geom_bar(stat = "identity", fill = "lavender", color = "black") + 
  geom_text(aes(label=per_label), vjust=-0.25) + 
  labs(x = "Source Page", y = "Count",  
       title = "Frequency of Each Source Page Accessed on the Application") + 
  scale_y_continuous(labels(scales::percent)) + 
  theme_bw() + 
  scale_x_discrete(labels = c("PICOL", "H&S", "H&S Supplement"))
```

## Activity in Each Label Section 
```{r activity-in-label-sections, echo=F, warning=F, message=F, results=F, eval=T, fig.width = 10, fig.height=10}
library(ggplot2)
library(tidyverse)

data <- data.frame(label = factor(c("Product Information", "PPE", "Pesticide Labels", "Health and Safety", "First Aid", "Producer Information", "Physical or Chemical Hazards", "Storage and Disposal", "Engineering Controls", "Environmental Protection", "Spray Drift Prevention" )),
                   count = c(1760, 1180, 914, 472, 464, 436, 356, 286, 278, 274, 262))

ggplot(data, aes(x = reorder(label, -count),y=count)) +
    geom_bar(stat="identity") + 
    scale_x_discrete(limits=(data$label)) + 
    geom_text(aes(label=count), hjust=-0.3) +
    coord_flip() + 
    xlab("Label Section") + 
    ylab("Count (n) ") + 
    ggtitle("¡Etiquetas de pesticidas, ahora!™/Pesticide Labels, Now!™ Views by Label Sections") 
```

## Frequency of Links Utilized 
```{r freq-of-links, echo=F, warning=F, message=F, eval=T, results=F, fig.width = 17, fig.height=10}
str(evViewPage.01)
per_data3 <- evViewPage.01 %>%
  count(evDesc1) %>% 
  mutate(per = n / sum(n),
         per_label = paste0(round(per*100), "%"))

ggplot(per_data3, aes(x = reorder(n, -per), y=per)) + 
  geom_bar(stat = "identity", fill = "lightblue", color = "black") + 
  geom_text(aes(label=per_label), vjust=-0.25) + 
  labs(x = "Links", y = "Count",  
       title = "Frequency of Links Utilized") + 
  scale_y_continuous(labels(scales::percent)) + 
  theme_bw()  + 
  scale_x_discrete(labels = c("Labels Search", "HS Label", "PICOL Search", "More", "Resources", "PICOL Label", "Feedback", "About", "EULA", "Partners", "Contact", "Disclaimer", "Privacy", "Update News"))
```

## Frequency of Different Links by Language
```{r freq-diff-links-by-language, echo=F, warning=F, message=F, eval=T, results=F, fig.width = 17, fig.height=10}
library(dplyr)
library(ggplot2)

tab <-  evViewPage.01 %>% group_by(evDesc1,evDesc2,.drop=FALSE) %>% tally()
tab %>% mutate(perc=n/sum(n)) %>% 
ggplot() + geom_col(aes(x=evDesc1,y=perc,fill=evDesc2),position="dodge") + 
scale_y_continuous(labels =scales::percent) +
labs(title = "Frequency of Different Links by Language", 
       x = "Links", 
       y = "Percentage") + 
  theme_classic() +
  scale_fill_brewer(palette = "Pastel1") 

```

## Table of Top Ten Searched Pesticides 
```{r searchedpesticides, warning=F, message=F, echo=F, results=T, eval=T}
library("dplyr")
table <- table(evDownload.01$prodName)
my_table <- table[order(table, decreasing = TRUE)]
my_table <- my_table[1:10] 
kable(my_table)
```


# Average Session Duration 
## 90.11 minutes
```{r session-duration, warning=F, message=F, echo=F, results=F, eval=F}
# Average session duration 
# sum(y$sessiontime)
# (7179658/60)
# 119661/1328
#90.11
```

\newpage
\pagenumbering{arabic}

# APPENDIX

<br>

# Data Dictionary 

## evDownload.01 subset

Unique devices (aid)

```{r unique-evDownload-users, echo=F, warning=F, message=F}

print(n_distinct(evDownload.01$aid), style="rmarkdown")

```

```{r evDownload-dictionary, echo=F, message=F, warnings=F, results='asis'}
tabl <- "
| Variable      | Description                    |
|---------------|--------------------------------|
| aid           | Random device identifier       |
| epaReg        | EPA regsistration number       |
| prodName      | Pesticide product name         |
| sourcePage    | App page visited?              |
| evType        | Action taken on app (download) |
| ts            | Timestamp yyy:mm:dd:hh:mm:ss   |
"
cat(tabl)
```

## evStart subset

Unique users (aid)

```{r unique-evStart-users, echo=F, warning=F, message=F}
print(n_distinct(evStart$aid), style="rmarkdown")
```

```{r evStart-dictionary, echo=F, message=F, warnings=F, results='asis'}
tabl <- "
| Variable      | Description                     |
|---------------|---------------------------------|
| aid           | Random device identifier        |
| evDesc1       | App version?                    |
| evDesc2       | Device type                     |
| evDesc3       | GPS coordinates                 |
| evType        | Action taken on app (start page) |
| ts            | Timestamp yyy:mm:dd:hh:mm:ss    |
"
cat(tabl)
```

## evViewPage.01 subset

Unique users (aid)

```{r unique-evViewpage-users, echo=F, warning=F, message=F}
print(n_distinct(evViewPage.01$aid), style="rmarkdown")
```

```{r evViewPage.01-dictionary, echo=F, message=F, warnings=F, results='asis'}
tabl <- "
| Variable      | Description                     |
|---------------|---------------------------------|
| aid           | Random device identifier        |
| evDesc1       | First action on app             |
| evDesc2       | English or Spanish              |
| evDesc3       | Pesticide label viewed          |
| evType        | Action taken on app (view page) |
| ts            | Timestamp yyy:mm:dd:hh:mm:ss    |
"
cat(tabl)
```

## Detailed variable descriptions

- Device = identified by a randomly assigned identifier. = Person. Person = device. There is no way to distinguish individual users. One device can be used by ≥ 1 person and 1 person can use ≥ 1 device.
- Access = accessed app = put PLN on device and opened app (app opens to label List).
- Session = time from when the app opened until just before next time it is opened.
- PICOL Searches = PICOL results viewed.
- Label searches = Label menu viewed.
- View = accessed and viewed information (any combination of ≥ 1 of the following)
- Label view = accessed + [(opened ≥ 1 label) + (opened ≥ 1 menu bar)] 
Label view + PDF = accessed + [(opened ≥ 1 label) + (opened ≥ 1 menu bar)+ (downloaded label PDF)] 
- PICOL view = accessed + [(conducted ≥ 1 PICOL search) + (viewed ≥ 1 PICOL result)]
- PICOL view + PDF  = accessed app + [(conducted ≥ 1 PICOL search) + (viewed ≥ 1 PICOL result) + (downloaded app)]
- General  view = accessed +(viewed label search page + selected a label, but did not open menu bar) and/or ( viewed PICOL search page) and/or viewed more pages
General  view + links
- Location = GPS coordinates. de-identified location in that it is somewhere within the ~ 500 ft radius. We will only report by broad areas. Agricultural regions if they are defined. Currently, many iPhone users are declining location as Apple is asking users if they want the location turned on/off with each update.  We may only be able to evaluate this up to the April release date.
 App is only available to devices registered in the US, CA, and MX. However, phones registered in these countries can be used anywhere. For example, we had a user connect from S. America from a US registered phone. 
- Population A definition: anyone that has accessed the app.  There is 1 excluded population and 3 study subpopulations (based on gps location coordinates at time the app is opened.)
    - Device used in WA state GPS data. (Not Seattle or King County)
    - Device used outside of WA state
    - No location (location services are off.)
    - Exclude. King County or at least the Seattle metropolitan area locations.  These are likely team and PNASH staff. Exclusion list. Selected random devices IDs are on an exclusion list. These are test devices. 

- Population B definition: (Only use if enough people respond to in app questions). Those users that respond to the location in-app question. (This response can be linked to app analytic data as it has the same random unique ID). This will be implemented very soon.
    - Response I work in WA state (not quite the same as where they downloaded it)
    - Response I work outside of Washington state
    - Do not want to answer
    - Skips answering the question.  (will combine with c)


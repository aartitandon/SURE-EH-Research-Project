---
title: "Pesticide Labels Now Report"
subtitle: "Draft"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    self_contained: yes
    toc: no
    toc_depth: 4
    toc_float: yes
  pdf_document:
    latex_engine: xelatex
    toc: yes
    toc_depth: 4
  md_document:
    toc: yes
  word_document:
    toc: yes
    toc_depth: '4'
editor_options: 
  chunk_output_type: console
---

```{r packages, warning=F, message=F, echo=F, results=F}

if(!require(pacman)) {install.packages("pacman")}
pacman::p_load(tidyverse, utils, lubridate, readxl, vcd, kableExtra, table1, summarytools, here, maps, sf, ggmap, sp, ggthemes, ggspatial, urbnmapr)

```

```{r setup, include=F, results='asis'}
#st_options(plain.ascii = F, # Always use this option in Rmd documents
style        = "rmarkdown", # Always use this option in Rmd documents
footnote     = NA,          # Makes html-rendered results more concise
subtitle.emphasis = F)  # Improves layout with some rmarkdown themes

```

```{r upload-clean-data, warning=F, message=F, echo=F, results=F}

temp <- list.files(path='Outputs', pattern="*.csv", full.names = T)

list2env(lapply(setNames(temp, make.names(gsub("*.csv$", "", temp))), read.csv), envir = .GlobalEnv)

colnames(Outputs.evStart.1)[1] <- "aid"
colnames(Outputs.evStart.1)[2] <- "evDesc1"
colnames(Outputs.evStart.1)[3] <- "evDesc2"
colnames(Outputs.evStart.1)[4] <- "evDesc3"
colnames(Outputs.evStart.1)[5] <- "evType"
colnames(Outputs.evStart.1)[6] <- "ts"

Outputs.evStart <- do.call(rbind, lapply(ls(pattern = "Outputs.evStart"), get))

rm(list = ls()[grep("^Outputs.evStart.", ls())])

#Filter out ignores

ignores <- read.csv("ignores.csv")

evDownload.01 <- filter(Outputs.evDownload.01,!(aid %in% ignores$aid))

evStart <- filter(Outputs.evStart,!(aid %in% ignores$aid))

evViewPage.01 <- filter(Outputs.evViewPage.01,!(aid %in% ignores$aid))

rm(Outputs.evDownload.01, Outputs.evStart, Outputs.evViewPage.01)

```

# Executive Summary

A data dictionary and descriptive statistics were prepared based on the Pesticide Labels Now (PLN) [analysis plan](https://docs.google.com/document/d/1mUHPYdpWljCWroODGenUjYlyae2ZWwqN4MScBLXlr2U/edit). For a better representation of users, we ignored a list of random identifiers ('aid' in *ignores.csv*) associated with the project team members and generated descriptive statistics for three subsets:

- evDownload.01
- evStart
- evViewPage.01

# Data Dictionary 

## evDownload.01 subset

Unique devices (aid)

```{r unique-evDownload-users, warning=F, message=F}
print(n_distinct(evDownload.01$aid), style="rmarkdown")
```

```{r evDownload-dictionary, echo=F, message=F, warnings=F, results='asis'}
tabl <- "
| Variable      | Description                    |
|---------------|--------------------------------|
| aid           | Random device identifier       |
| epaReg        | EPA regsistration number       |
| prodName      | Pesticide product name         |
| sourcePage    | App page visited?              |
| evType        | Action taken on app (download) |
| ts            | Timestamp yyy:mm:dd:hh:mm:ss   |
"
cat(tabl)
```

## evStart subset

Unique users (aid)

```{r unique-evStart-users, warning=F, message=F}
print(n_distinct(evStart$aid), style="rmarkdown")
```

```{r evStart-dictionary, echo=F, message=F, warnings=F, results='asis'}
tabl <- "
| Variable      | Description                     |
|---------------|---------------------------------|
| aid           | Random device identifier        |
| evDesc1       | App version?                    |
| evDesc2       | Device type                     |
| evDesc3       | GPS coordinates                 |
| evType        | Action taken on app (start page) |
| ts            | Timestamp yyy:mm:dd:hh:mm:ss    |
"
cat(tabl)
```

## evViewPage.01 subset

Unique users (aid)

```{r unique-evViewpage-users, warning=F, message=F}
print(n_distinct(evViewPage.01$aid), style="rmarkdown")
```

```{r evViewPage.01-dictionary, echo=F, message=F, warnings=F, results='asis'}
tabl <- "
| Variable      | Description                     |
|---------------|---------------------------------|
| aid           | Random device identifier        |
| evDesc1       | First action on app             |
| evDesc2       | English or Spanish              |
| evDesc3       | Pesticide label viewed          |
| evType        | Action taken on app (view page) |
| ts            | Timestamp yyy:mm:dd:hh:mm:ss    |
"
cat(tabl)
```

## Detailed variable descriptions

- Device = identified by a randomly assigned identifier. = Person. Person = device. There is no way to distinguish individual users. One device can be used by ≥ 1 person and 1 person can use ≥ 1 device.
- Access = accessed app = put PLN on device and opened app (app opens to label List).
- Session = time from when the app opened until just before next time it is opened.
- PICOL Searches = PICOL results viewed.
- Label searches = Label menu viewed.
- View = accessed and viewed information (any combination of ≥ 1 of the following)
- Label view = accessed + [(opened ≥ 1 label) + (opened ≥ 1 menu bar)] 
Label view + PDF = accessed + [(opened ≥ 1 label) + (opened ≥ 1 menu bar)+ (downloaded label PDF)] 
- PICOL view = accessed + [(conducted ≥ 1 PICOL search) + (viewed ≥ 1 PICOL result)]
- PICOL view + PDF  = accessed app + [(conducted ≥ 1 PICOL search) + (viewed ≥ 1 PICOL result) + (downloaded app)]
- General  view = accessed +(viewed label search page + selected a label, but did not open menu bar) and/or ( viewed PICOL search page) and/or viewed more pages
General  view + links
- Location = GPS coordinates. de-identified location in that it is somewhere within the ~ 500 ft radius. We will only report by broad areas. Agricultural regions if they are defined. Currently, many iPhone users are declining location as Apple is asking users if they want the location turned on/off with each update.  We may only be able to evaluate this up to the April release date.
 App is only available to devices registered in the US, CA, and MX. However, phones registered in these countries can be used anywhere. For example, we had a user connect from S. America from a US registered phone. 
- Population A definition: anyone that has accessed the app.  There is 1 excluded population and 3 study subpopulations (based on gps location coordinates at time the app is opened.)
    - Device used in WA state GPS data. (Not Seattle or King County)
    - Device used outside of WA state
    - No location (location services are off.)
    - Exclude. King County or at least the Seattle metropolitan area locations.  These are likely team and PNASH staff. Exclusion list. Selected random devices IDs are on an exclusion list. These are test devices. 

- Population B definition: (Only use if enough people respond to in app questions). Those users that respond to the location in-app question. (This response can be linked to app analytic data as it has the same random unique ID). This will be implemented very soon.
    - Response I work in WA state (not quite the same as where they downloaded it)
    - Response I work outside of Washington state
    - Do not want to answer
    - Skips answering the question.  (will combine with c)

# Descriptive Statistics

## evDownload.01

```{r evDownload-summary, warning=F, message=F, echo=F, results='asis'}

print(freq(evDownload.01$prodName, report.nas = F, totals = T, cumul = F, headings = T, order="freq", style = 'rmarkdown'))

print(freq(evDownload.01$sourcePage, report.nas = F, totals = T, cumul = F, headings = T, order="freq", style = 'rmarkdown'))

print(freq(evDownload.01$evType, report.nas = F, totals = T, cumul = F, headings = T, order="freq", style = 'rmarkdown'))

#print(ctable(x = evDownload.01$evType, y = evDownload.01$sourcePage, prop = "r", style='rmarkdown'))

#print(freq(evDownload.01$aid, report.nas = F, totals = T, cumul = F, headings = T, order="freq"), method="render")

```

## evStart

```{r evStart-summary, warning=F, message=F, echo=F, results='asis'}

print(freq(evStart$evDesc1, report.nas = F, totals = T, cumul = F, headings = T, order="freq", style = 'rmarkdown'))

#Tally device type using evDesc2 (all sessions)

evStart$evDesc2 <- as.character(evStart$evDesc2)

s <- strsplit(evStart$evDesc2, split = ",")

evStart$device_cat <- unlist(purrr::map(s, 1))

rm(s)

#Tally device types using evDesc2 (unique aid)

evStart.unique.device <- evStart %>%
  distinct_at(vars(aid), .keep_all = TRUE)

print(freq(evStart.unique.device$device_cat, report.nas = F, totals = T, cumul = F, headings = T, order="freq", style = 'rmarkdown'))

#print(freq(evStart$evDesc3, report.nas = F, totals = T, cumul = F, headings = T, order="freq"), method="render")

#print(freq(evStart$evType, report.nas = F, totals = T, cumul = F, headings = T, order="freq", style = 'rmarkdown'))

#print(freq(evStart$aid, report.nas = F, totals = T, cumul = F, headings = T, order="freq"), method="render")

```

## evViewPage.01

```{r evViewPage-summary, warning=F, message=F, echo=F, results='asis'}

print(freq(evViewPage.01$evDesc1, report.nas = F, totals = T, cumul = F, headings = T, order="freq", style = 'rmarkdown'))

print(freq(evViewPage.01$evDesc2, report.nas = F, totals = T, cumul = F, headings = T, order="freq", style = 'rmarkdown'))

print(freq(evViewPage.01$evDesc3, report.nas = F, totals = T, cumul = F, headings = T, order="freq", style = 'rmarkdown'))

print(freq(evViewPage.01$evType, report.nas = F, totals = T, cumul = F, headings = T, order="freq", style = 'rmarkdown'))

#print(freq(evViewPage.01$aid, report.nas = F, totals = T, cumul = F, headings = T, order="freq"), method="render")

```

# App use by location 

evStart; Aug 2020 - April 2021

```{r user-map-us, warning=F, message=F, echo=F, eval=T, out.width = "100%"}

#extract locations from evStart

## Remove parthenthesis from evDesc3 lat, long
evStart$evDesc3sub <- gsub("[()]", "", evStart$evDesc3)

## Separate lat/long
evStart <- evStart %>%
     filter(evDesc3sub != '0,0') %>%
     separate(evDesc3sub, into = c('lat','lon'), sep=",")

gps <- select(evStart, lat, lon)
gps <- na.omit(gps)
gps <- gps[gps$lat != NaN, ]
gps$lat <- as.numeric(gps$lat)
gps$lon <- as.numeric(gps$lon)

pln_sf <- gps %>% st_as_sf(coords = c("lon","lat"), crs=4326)
pln_sf_t <- st_transform(pln_sf, crs=2163)

states_sf <- get_urbn_map(map = "states", sf = T)

#Plot for US sessions

ggplot() + 
  geom_sf(data = pln_sf_t, color="red", size=1) + 
  geom_sf(data = states_sf, fill=NA, color="black", size=0.1, alpha=0) +
  coord_sf(datum = st_crs(2163)) +
  labs(fill = "", title="", caption="") + scale_x_continuous(limits = c(-3e+06, 3e+06)) +
    scale_y_continuous(limits = c(-3e+06, 1e+06)) + theme_nothing() 


```

```{r user-map-wa, warning=F, message=F, echo=F, eval=T, out.width = "100%"}

#Plot for WA sessions

counties_sf <- get_urbn_map(map = "counties", sf = T)

pln_sf_t <- st_transform(pln_sf, crs=2285)
counties_sf_t <- st_transform(counties_sf, crs=2285)

t <- counties_sf_t %>%
  filter(state_name == "Washington")

ggplot() + 
  geom_sf(data = pln_sf_t, color="red", size=1) + 
  geom_sf(data = t, fill=NA, color="black", size=0.1, alpha=0) +
  coord_sf(datum = st_crs(2285)) +
  labs(fill = "", title="", caption="") + scale_x_continuous(limits = c(0.6e+06, 2.7e+06)) +
    scale_y_continuous(limits = c(-0.7e+06, 0.8e+06)) + theme_nothing()

# https://spatialreference.org/ref/epsg/?search=washington&srtext=Search

# https://www.nceas.ucsb.edu/sites/default/files/2020-04/OverviewCoordinateReferenceSystems.pdf

#+ annotation_scale(location = "bl") + annotation_north_arrow(location = "bl", which_north = "true", style = north_arrow_fancy_orienteering)

```


# Device time use patterns

```{r heat-map-time-series, warning=F, message=F, echo=F} 

#all accesses by date

#https://towardsdatascience.com/time-series-calendar-heatmaps-9f576578fcfe

#calendar day x individual

#https://www.littlemissdata.com/blog/heatmaps

```

# Dataframe summaries

```{r summary, warning=F, message=F, echo=F}

print(dfSummary(evDownload.01), method = "render")
print(dfSummary(evStart), method = "render")
print(dfSummary(evViewPage.01), method = "render")
print(dfSummary(Outputs.h.s.label.view.counts), method = "render")
print(dfSummary(Outputs.HS.DLS.2021), method = "render")
print(dfSummary(Outputs.PICOL.DLS.2021), method = "render")

```

# merged.csv dataframe 
```{r upload-merged-monthly-csvs, warning=F, message=F, echo=F, results=F}
temp <- list.files(path='CSV', pattern="*.csv", full.names = T)
list2env(lapply(setNames(temp, make.names(gsub("*.csv$", "", temp))), read.csv), envir = .GlobalEnv)
rm(CSV.qAnswers)
merged.csv <- do.call(rbind, lapply(ls(pattern = "CSV"), get))
ignores <- read.csv("ignores.csv")
merged.csv <- filter(merged.csv,!(aid %in% ignores$aid))
```

#aarti's practice chunks
```{r}
# (add/remove) changing variable names 
names(evViewPage.01) <- NULL 
names(evViewPage.01) <- c("Device", "Links", "Language", "evDesc3", "SourceLink", "Date")

# "Frequency of Different Links by Language Graph"
install.packages("ggplot2")
ggplot(evViewPage.01) + 
  geom_bar(aes(x=Language, fill=Links)) + ggtitle(label = "Frequency of Different Links by Language") + 
  labs(x = "Language",
       y= "Count")
 
# Attempt 2 
ggplot(evViewPage.01) + 
  geom_bar(aes(x=Language, fill=Links)) + geom_col(position = "dodge")

#convert data into percentages 
evViewPage.01_percentages <- t(prop.table(table(evViewPage.01$Language))) *100
barplot(evViewPage.01_percentages, ylab = "Percent")

install.packages("scales")
library("scales")
```


```{r}
# _______________________________________________________________________________

# Percentage of total interactions in English Versus Spanish 
ggplot(evViewPage.01, aes(Language)) + 
  geom_bar(aes(y = (..count..)/sum(..count..))) + 
  scale_y_continuous(labels = percent)

# _______________________________________________________________________________
```


```{r}
evViewPage.01 %>%
  filter(Language == "en" |
           Language == "es") %>%
  #drop_na(Links) %>%
  ggplot(aes(Language, fill = Links)) + 
  geom_bar(position = "dodge", 
           alpha = 0.5) + 
  theme_bw()+
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) + 
  labs(title = "Frequency of Different Links by Language", 
       x = "Language", 
       y = "Count")  + 
  scale_x_discrete(labels = c("English", "Spanish")) 


# __________________________________________________________________________________________
ggplot(evViewPage.01, aes(Links) ) +
  geom_bar() + facet_grid(Language ~ .) + 
  labs(title = "Frequency of Different Links by Language", 
       x = "Links", 
       y = "Count")  
# __________________________________________________________________________________________
ggplot(data = evViewPage.01, mapping = aes(x=Language, fill=Links)) +
  geom_bar(stat="identity", position = "dodge")
# __________________________________________________________________________________________
evViewPage.01 %>%
  #Change to long format
  pivot_longer(cols = c(Links,Language),
               names_to = "var") %>%
  group_by(value, var) %>%
  #Get the frequencies of A, B, Boy and Girl
  count() %>%
  ungroup() %>%
  #Group by var, which now has level Col1 and Col2
  group_by(var) %>%
  #Calculate proportion
  mutate(perc = n / sum (n))

ggplot(evViewPage.01, aes(x = var, 
                y = perc,
                fill = value)) + 
  geom_col(position = "dodge")
# __________________________________________________________________________________________


tab <-  evViewPage.01 %>% group_by(Links,Language,.drop=FALSE) %>% tally()
tab %>% mutate(perc=n/sum(n)) %>% 
ggplot() + geom_col(aes(x=Links,y=perc,fill=Language),position="dodge") + 
scale_y_continuous(labels =scales::percent) +
labs(title = "Frequency of Different Links by Language", 
       x = "Links", 
       y = "Percentage") + 
  theme_classic() +
  scale_fill_brewer(palette = "Pastel1") 


# __________________________________________________________________________________________


ggplot(df1, aes(x = var, 
                y = perc,
                fill = value)) + 
  geom_col(position = "dodge")
evViewPage.01 %>%
  filter(Language == "en") %>%
  #drop_na(Links) %>%
  ggplot(aes(Language, fill = Links)) + 
  geom_bar(position = "dodge", 
           alpha = 0.5) + 
  facet_wrap(~Language) + 
  theme_bw()+
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) + 
  labs(title = "Title", 
       x = "Language", 
       y = "Count")

evViewPage.01 %>%
  filter(Language == "es") %>%
  #drop_na(Links) %>%
  ggplot(aes(Language, fill = Links)) + 
  geom_bar(position = "dodge", 
           alpha = 0.5) + 
  facet_wrap(~Language) + 
  theme_bw()+
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) + 
  labs(title = "Title", 
       x = "Language", 
       y = "Count")

evViewPage.01 %>%
  filter(Language == "en"| Language == "es") %>%
  #drop_na(Links) %>%
  ggplot(aes(Language, fill = Links)) + 
  geom_bar(aes(y=..prop..,fill=factor(..x..)),stat="count") + 
  #facet_wrap(~Language) + 
  theme_bw()+
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) + 
  labs(title = "Frequency of Different Links by Language", 
       x = "Language", 
       y = "Count") + 
  scale_x_discrete(labels = c("English", "Spanish")) + 
  geom_text(aes(label=after_stat("prop*100")))
       
```

```{r}
# Attempt #2 at frquency of links with each language 

table(evViewPage.01$Links)

str(evViewPage.01)
per_data <- evViewPage.01 %>%
  count(Links) %>% 
  mutate(per = n / sum(n),
         per_label = paste0(round(per*100), "%"))

ggplot(per_data, aes(x = reorder(n, -per), y=per)) + 
  geom_bar(stat = "identity", fill = "lightblue", color = "black") + 
  geom_text(aes(label=per_label), vjust=-0.25) + 
  labs(x = "Links", y = "Count",  
       title = "Overall Frequency of Links") + 
  scale_y_continuous(labels(scales::percent)) + 
  theme_bw()  + 
  scale_x_discrete(labels = c("Labels Search", "HS Label", "PICOL Search", "More", "Resources", "PICOL Label", "Feedback", "About", "EULA", "Partners", "Contact", "Disclaimer", "Privacy", "Update News"))


```



```{r}

# How many devices used android versus iOS?

Devices=select(evStart,3)
install.packages("dplyr")
Devices %>% group_by(evDesc2)

Devices$evDesc2
table(Devices$evDesc2)
# iOS = 8349 
# android = 2871

```

```{r}

# Frequency of Labels 

# narrow evDownload.01 to just product name 
install.packages("dpylr")
library("dpylr")

evDownload.01 %>% 
  group_by(prodName) %>%
  summarise(n=n())


library("dplyr")
newtable <- (evDownload.01$prodName)
newtable
sort(newtable, decreasing = TRUE)
sort(evDownload.01$prodName)
table(evDownload.01$prodName)


install.packages("gmodels")
library(gmodels)
ctable(evDownload.01$prodName, evDownload.01$sourcePage)

#table function: two-way table 
table(evDownload.01$prodName, evDownload.01$sourcePage)

#table function: three-way table 
table(evDownload.01$prodName, evDownload.01$sourcePage)

knitr::kable(evDownload.01, "pipe", col.name=c"Devices", "EPA Regulation", "Product Name", "Source Page", "ev Type", "Date"), align=c("l", "c", "c"))

#install.packages("huxtable")
#library(huxtable)
#huxtable(evDownload.01$prodName, evDownload.01$sourcePage)

install.packages("gt")
install.packages("gtsummary")
head(evDownload.01)
ProductNames <- evDownload.01 %>% select(prodName, sourcePage)

gtsummary(evDownload.01)


ProductNames=filter(evDownload.01, prodName=="ProductNames")

LabelsSearch %>% group_by(evDesc2) %>% tally(sort=T)

```


```{r}
# Frequency of Language Accessed on App 
install.packages("breakDown")
install.packages ("dplyr")
install.packages("expm")

library("dplyr")
count_Language <- evViewPage.01 %>%
  count(Language)


ggplot(count_Language, aes(x=reorder(Language, -n), y=n)) +
  geom_bar(stat = "identity", fill = "blue", color = "black") + 
  geom_text(aes(label=n), vjust = -0.25) + 
  labs(x = "Language", y = "Count", title = "Frequency of Different Links by Language")

# __________________________________________________________________________________________

# Percentage of Language Accessed on the App 
str(evViewPage.01)
per_data <- evViewPage.01 %>%
  count(Language) %>% 
  mutate(per = n / sum(n),
         per_label = paste0(round(per*100), "%"))

ggplot(per_data, aes(x = reorder(n, -per), y=per)) + 
  geom_bar(stat = "identity", fill = "lightblue", color = "black") + 
  geom_text(aes(label=per_label), vjust=-0.25) + 
  labs(x = "Language", y = "Count",  
       title = "Frequency of Each Language Accessed on the Application") + 
  scale_y_continuous(labels(scales::percent)) + 
  theme_bw() + 
  scale_x_discrete(labels = c("English", "Spanish"))


```

# __________________________________________________________________________________________

```{r}
# Frequency of Source Page 

evDownload.01 %>% group_by(prodName) %>% summarise(N=n())

table(evDownload.01$sourcePage)

str(evDownload.01)
per_data <- evDownload.01 %>%
  count(sourcePage) %>% 
  mutate(per = n / sum(n),
         per_label = paste0(round(per*100), "%"))

ggplot(per_data, aes(x = reorder(n, -per), y=per)) + 
  geom_bar(stat = "identity", fill = "lavender", color = "black") + 
  geom_text(aes(label=per_label), vjust=-0.25) + 
  labs(x = "Source Page", y = "Count",  
       title = "Frequency of Each Source Page Accessed on the Application") + 
  scale_y_continuous(labels(scales::percent)) + 
  theme_bw() + 
  scale_x_discrete(labels = c("PICOL", "H&S", "H&S Supplement"))


```

```{r}
# What type of devices are being used 
table(evStart$device_cat)

str(evStart)
per_data <- evStart %>%
  count(device_cat) %>% 
  mutate(per = n / sum(n),
         per_label = paste0(round(per*100), "%"))

ggplot(per_data, aes(x = reorder(n, -per), y=per)) + 
  geom_bar(stat = "identity", fill = "darkseagreen1", color = "black") + 
  geom_text(aes(label=per_label), vjust=-0.25) + 
  labs(x = "Devices", y = "Count",  
       title = "Devices Utilized to Access the Application") + 
  scale_y_continuous(labels(scales::percent)) + 
  theme_bw() + 
  scale_x_discrete(labels = c("iPhone", "Android", "iPad", "Pixel 3a: Android 10"))
```

# Attempts at Kit's Table 

```{r}
# New dataframe of device_cat + aid = device_cat_aid 
device_cat_aid <- unique(evStart[ , c("aid", "device_cat")])

test <- left_join(evDownload.01, device_cat_aid, by="aid") 

```

```{r}
#Tally device type using evDesc2 (all sessions)
#Restrict code to unique event descriptions, then filter observations based on characters 

device <- filter(merged.csv, (str_detect(evDesc2, 'Pixel|iphone|ipad|android'))) %>% 
  distinct_at(vars(aid), .keep_all = TRUE) 

device$evDesc2 <- as.character(device$evDesc2)
s <- strsplit(device$evDesc2, split = ",")
device$device_cat <- unlist(purrr::map(s, 1))
rm(s)

unique.aid.device <- device %>%
  distinct_at(vars(aid), .keep_all = TRUE) 

unique.aid.device <- unique.aid.device %>% 
  select(aid, device_cat)

unique.aid.device.language <- left_join(unique.aid.device.language, unique.aid.device, by="aid") 
unique.aid.device.language <- filter(unique.aid.device.language, (str_detect(evDesc1, 'Labels Search'))) %>%
  distinct_at(vars(aid), .keep_all = TRUE) %>%
  

# left join 
# merge 
#make sure you don't count same device twice 

```

```{r}
# New dateframe combining unique.aid.device with its corresponding language use

language <- filter(merged.csv, (str_detect(evDesc2, 'en|es')))
language$evDesc2 <- as.character(language$evDesc2)
language <- filter(language, (str_detect(evDesc2, 'es=>en|en=>es', negate = TRUE))) %>%
  distinct_at(vars(aid), .keep_all = TRUE) 
language <- left_join(language, device, by="aid") 

# 


#s <- strsplit(language$evDesc2, ! = "es=>en")
#language$device_cat <- unlist(purrr::map(s, 1))
#rm(s)

unique.aid.device.language <- language %>%
  distinct_at(vars(aid), .keep_all = TRUE) 

unique.aid.device.language <- unique.aid.device.language %>% 
  select(aid, device_cat)

unique.aid.device.language <- filter(unique.aid.device.language, (str_detect(evDesc1, 'Labels Search')))
unique.aid.device.language.2 <- left_join(unique.aid.device.language, unique.aid.device, by="aid") 

```


```{r}
# Table 1. Percent of new users to access the app ¡Etiquetas de pesticidas, ahora!™/Pesticide Labels, Now!  by operating system and language and operating system (N = xx)

#merge two data frames 
jointdataset <- merge(unique.aid.device, unique.aid.device.language, by = 'aid')
table(jointdataset$device_cat.x, jointdataset$evDesc2.x)
```

```{r}
# Table 2. Percent of ¡Etiquetas de pesticidas, ahora!™/Pesticide Labels, Now!™ sessions by operating system and languageb and operating system.

# New dateframe sorting evViewPage.01's unique aid and language, but how do I do time? 
unique.evViewPage <- unique(evViewPage.01[ , c("aid", "evDesc2", "ts")])

# format 'filterevent's' date and time 
install.packages("lubridate")
library("lubridate")
merged.csv$ts <- ymd_hms(merged.csv$ts)

#filter merged.csv from aid's first "evStart" to the next "evStart"
sessionid <- merged.csv %>%
  group_by(aid) %>%
  slice(evType == "EvStart")

##
install.packages("dplyr")
library("dplyr")

merged.csv.dedup <- unique(merged.csv)

x <- merged.csv.dedup %>% 
  group_by(sessionid = cumsum(evType == 'evStart')) %>% 
  mutate(sessioneventno = row_number())

# this list numbers the rows of data frame groups with dplyr Package
numberedevents <- merged.csv %>%         #Create numbering variable
  group_by(evType == "evStart") %>%
  mutate(numbering = row_number())
numberedevents

# OR 
#this list puts it in order by aid, date with its accompanying eventType, and Language 
unique.merged.csv <- unique(merged.csv[ c("aid", "evType", "ts")])

#this list filters eventTypes to just evStart and evViewPage 
filterevents <- filter(unique.merged.csv, (str_detect(evType, 'evStart|evViewPage')))

#
dos <- filter(numberedevents, numbering =="2")
dos <- left_join(dos, unique.evViewPage, by="ts")

table(dos$evDesc2)

# Notes: 
# identify event of interest and label it "timepoint1"
# event 1 is "evStart" 
# event 2 is "evViewpage" 
# number all the way through until the next session 
# count the number of events sequentially (counter?)
# filter when counter = 2 
# to determine how long their session is: the countup would reach up till the next session? 
# order data consequentially, everytime u see evStart give it a new number 
# 

```

```{r}
# Table 3. Percent of ¡Etiquetas de pesticidas, ahora!™/Pesticide Labels, Now!™ sessionsa by and languageb and main menu items.
# Main Menu Items - Label Search, PICOL, Resources, and More 
table(evViewPage.01$Links, evViewPage.01$Language)
```

```{r}
# Table 4. Percent of ¡Etiquetas de pesticidas, ahora!™/Pesticide Labels, Now!™ sessionsa by and languageb and label sections. 
table(merged.csv$evDesc3)
table4 <-  merged.csv %>% group_by(evDesc3,evDesc1,.drop=FALSE) %>% tally()

table4 %>% mutate(perc=n/sum(n)) %>% 
  
table4 <- table(table4)
```

```{r}
# Table 5. Product labels viewed and downloaded through the Pesticide Labels section of the ¡Etiquetas de pesticidas, ahora!™/Pesticide Labels, Now!™app

# Searched 
install.packages("dplyr")
table5.searched <- filter(evViewPage.01, (str_detect(Links, 'HS Label')))
final.table5.searched <- table5.searched %>% group_by(evDesc3) %>% tally(sort = T)

# Viewed 
table5.viewed <- filter(evDownload.01, (str_detect(sourcePage, 'H&S')))
viewed$sourcePage <- as.character(viewed$sourcePage)
table5.viewed <- filter(table5.viewed, (str_detect(sourcePage, 'Supplement', negate = TRUE)))
final.table5.viewed <- table5.viewed %>% group_by(prodName) %>% tally(sort=T)

# 
# Is evViewPage.01, evDownload.01 updated? Ask Dennis to upload all the way through the recordeed period (August 31st)
# or... recreate those subsets from the merged.csv
# even merged.csv ends in June 2021.. ask dennis? 
# re - pull the data before asking 
```

```{r}
# Table 6. Product Labels accessed and downloaded through the Main menu item, PICOL Search,  in the ¡Etiquetas de pesticidas, ahora!™/Pesticide Labels, Now!™ app

#Searched
table6.searched <- filter(evViewPage.01, (str_detect(Links, 'PICOL Label')))
final.table6.searched <- table6.searched %>% group_by(evDesc3) %>% tally(sort=T)

#Viewed 
table6.viewed <- filter(evDownload.01, (str_detect(sourcePage, 'PICOL')))
final.table6.viewed <- table6.viewed %>% group_by(prodName) %>% tally(sort=T)

```

```{r}
# Table 7. Frequency of Spanish/English toggle use. by¡Etiquetas de pesticidas, ahora!™/Pesticide Labels, Now!™users

# Count of all toggles 
alltoggles <- filter(merged.csv, (str_detect(evDesc2, 'es=>en|en=>es')))
alltoggles.1 <- alltoggles %>% group_by(evDesc2) %>% tally(sort=T)

# "at least one toggle from start session"
aid.languagetoggle <- alltoggles %>% 
  distinct_at(vars(aid), .keep_all = TRUE) 

table7 <- aid.languagetoggle %>%
  group_by(evDesc2) %>%
  tally(sort=T)

```

```{r}
# New Chunk for Table 1 

```

```{r}
# New Chunk for Table 2 

evViewPage.01_language <- evViewPage.01 %>% 
  distinct_at(vars(device), .keep_all = TRUE)



unique.aid.device.language <- unique.aid.device.language %>% 
  select(aid, device_cat)

```

```{r}
# Table 4 Bar Graph 
data <- data.frame(label = factor(c("Product Information", "PPE", "Pesticide Labels", "Health and Safety", "First Aid", "Producer Information", "Physical or Chemical Hazards", "Storage and Disposal", "Engineering Controls", "Environmental Protection", "Spray Drift Prevention" )),
                   count = c(1760, 1180, 914, 472, 464, 436, 356, 286, 278, 274, 262))

install.packages("tidyverse")
install.packages("ggplot2")
library(ggplot2)
library(tidyverse)

g <- (ggplot2::ggplot(data, ggplot2::aes(x=label, y=count))
        + ggplot2::geom_bar(stat="identity")
        + ggplot2::scale_x_discrete(limits=rev(data$label))
        + ggplot2::coord_flip()) 

g

ggplot(data, aes(x = reorder(label, -count),y=count)) +
    geom_bar(stat="identity") + 
    scale_x_discrete(limits=(data$label)) + 
    geom_text(aes(label=count), hjust=-0.3) +
    coord_flip() + 
    xlab("Label Section") + 
    ylab("Count (n) ") + 
    ggtitle("¡Etiquetas de pesticidas, ahora!™/Pesticide Labels, Now!™ Views by Label Sections") 
  
```

